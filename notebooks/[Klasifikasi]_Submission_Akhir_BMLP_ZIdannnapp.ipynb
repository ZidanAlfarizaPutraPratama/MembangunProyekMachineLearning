{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fKADPWcFKlj3"
   },
   "source": [
    "# **1. Import Library**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LgA3ERnVn84N"
   },
   "source": [
    "Pada tahap ini, Anda perlu mengimpor beberapa pustaka (library) Python yang dibutuhkan untuk analisis data dan pembangunan model machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "BlmvjLY9M4Yj"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.cluster import KMeans\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f3YIEnAFKrKL"
   },
   "source": [
    "# **2. Memuat Dataset dari Hasil Clustering**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ey3ItwTen_7E"
   },
   "source": [
    "Memuat dataset hasil clustering dari file CSV ke dalam variabel DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "GHCGNTyrM5fS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['symbol', 'account', 'type', '2020', '2021', '2022', '2023', 'Cluster'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('../data/clustered_data.csv')\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KkPem5eWL2UP"
   },
   "source": [
    "# **3. Data Splitting**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YYj1rl_JNI9Y"
   },
   "source": [
    "Tahap Data Splitting bertujuan untuk memisahkan dataset menjadi dua bagian: data latih (training set) dan data uji (test set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "OubAW-7ONKVj"
   },
   "outputs": [],
   "source": [
    "# Pastikan kolom numerik sudah ada untuk proses clustering\n",
    "if not all(col in data.columns for col in ['2020', '2021', '2022', '2023']):\n",
    "    raise ValueError(\"Dataset tidak memiliki kolom tahun yang diperlukan.\")\n",
    "\n",
    "# Mengatasi nilai NaN: menghapus baris dengan NaN\n",
    "data = data.dropna(subset=['2020', '2021', '2022', '2023'])\n",
    "\n",
    "# Fitur dan label\n",
    "X = data[['2020', '2021', '2022', '2023']]\n",
    "y = data['type']  # Menggunakan 'type' sebagai label\n",
    "\n",
    "# Bagi data menjadi set pelatihan dan pengujian\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IVPbB03CMhTT"
   },
   "source": [
    "# **4. Membangun Model Klasifikasi**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ned1pL9zMmBK"
   },
   "source": [
    "## **a. Membangun Model Klasifikasi**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WAWzPOE4Nkti"
   },
   "source": [
    "Setelah memilih algoritma klasifikasi yang sesuai, langkah selanjutnya adalah melatih model menggunakan data latih.\n",
    "\n",
    "Berikut adalah rekomendasi tahapannya.\n",
    "1. Pilih algoritma klasifikasi yang sesuai, seperti Logistic Regression, Decision Tree, Random Forest, atau K-Nearest Neighbors (KNN).\n",
    "2. Latih model menggunakan data latih."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4JYxBe87NLDk"
   },
   "outputs": [],
   "source": [
    "# Model Random Forest\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Hyperparameter tuning\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'max_depth': [5, 10, None],\n",
    "    'min_samples_split': [2, 5]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, scoring='f1_weighted', cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Dapatkan model terbaik\n",
    "best_model = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "seYoHNY3XU1y"
   },
   "source": [
    "Tulis narasi atau penjelasan algoritma yang Anda gunakan.\n",
    "\n",
    "**Narasi**: Algoritma Random Forest dipilih karena kemampuannya dalam menangani data dengan baik dan mengurangi risiko overfitting. Algoritma ini bekerja dengan membangun banyak pohon keputusan (decision trees) dan menggabungkan hasilnya untuk meningkatkan akurasi dan kontrol terhadap overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ergzChZFEL-O"
   },
   "source": [
    "## **b. Evaluasi Model Klasifikasi**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zOm68u-7NpLT"
   },
   "source": [
    "Berikut adalah **rekomendasi** tahapannya.\n",
    "1. Lakukan prediksi menggunakan data uji.\n",
    "2. Hitung metrik evaluasi seperti Accuracy dan F1-Score (Opsional: Precision dan Recall).\n",
    "3. Buat confusion matrix untuk melihat detail prediksi benar dan salah."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tMq4QAssNLip"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 1.00\n",
      "Train F1-Score: 1.00\n",
      "Test Accuracy: 1.00\n",
      "Test F1-Score: 1.00\n",
      "\n",
      "Laporan Klasifikasi (Test Set):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     13028\n",
      "           1       1.00      1.00      1.00         1\n",
      "           2       1.00      1.00      1.00        31\n",
      "\n",
      "    accuracy                           1.00     13060\n",
      "   macro avg       1.00      1.00      1.00     13060\n",
      "weighted avg       1.00      1.00      1.00     13060\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[13028     0     0]\n",
      " [    0     1     0]\n",
      " [    0     0    31]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# 1. Memuat dataset\n",
    "data = pd.read_csv('../data/combined_financial_data_idx.csv')\n",
    "\n",
    "# 2. Mengatasi nilai NaN\n",
    "data = data.dropna(subset=['2020', '2021', '2022', '2023'])\n",
    "\n",
    "# 3. Melakukan pengelompokan (clustering)\n",
    "clustering_data = data[['2020', '2021', '2022', '2023']]\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "data['Cluster'] = kmeans.fit_predict(clustering_data)\n",
    "\n",
    "# 4. Fitur dan label\n",
    "X = data[['2020', '2021', '2022', '2023']]\n",
    "y = data['Cluster']\n",
    "\n",
    "# 5. Bagi data menjadi set pelatihan dan pengujian\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 6. Model Random Forest\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# 7. Hyperparameter tuning dengan GridSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'max_depth': [5, 10, None],\n",
    "    'min_samples_split': [2, 5]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, scoring='f1_weighted', cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# 8. Dapatkan model terbaik dari grid search\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# 9. Lakukan prediksi menggunakan data uji\n",
    "y_pred_train = best_model.predict(X_train)\n",
    "y_pred_test = best_model.predict(X_test)\n",
    "\n",
    "# 10. Hitung metrik evaluasi seperti Accuracy dan F1-Score\n",
    "train_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "train_f1 = f1_score(y_train, y_pred_train, average='weighted')\n",
    "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "test_f1 = f1_score(y_test, y_pred_test, average='weighted')\n",
    "\n",
    "# 11. Hasil evaluasi\n",
    "print(f'Train Accuracy: {train_accuracy:.2f}')\n",
    "print(f'Train F1-Score: {train_f1:.2f}')\n",
    "print(f'Test Accuracy: {test_accuracy:.2f}')\n",
    "print(f'Test F1-Score: {test_f1:.2f}')\n",
    "\n",
    "# 12. Laporan klasifikasi\n",
    "print(\"\\nLaporan Klasifikasi (Test Set):\")\n",
    "print(classification_report(y_test, y_pred_test))\n",
    "\n",
    "# 13. Confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_test)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H4_9OwrsXZlz"
   },
   "source": [
    "## 3. Perbandingan Hasil\n",
    "\n",
    "- **Random Forest** \n",
    "  - Train Accuracy: 1.00\n",
    "  - Train F1-Score: 1.00\n",
    "  - Test Accuracy: 1.00\n",
    "  - Test F1-Score: 1.00\n",
    "\n",
    "  **Laporan Klasifikasi (Test Set):**\n",
    "  ```\n",
    "                precision    recall  f1-score   support\n",
    "\n",
    "             0       1.00      1.00      1.00     13028\n",
    "             1       1.00      1.00      1.00         1\n",
    "             2       1.00      1.00      1.00        31\n",
    "\n",
    "      accuracy                           1.00     13060\n",
    "     macro avg       1.00      1.00      1.00     13060\n",
    "  weighted avg       1.00      1.00      1.00     13060\n",
    "  ```\n",
    "\n",
    "  **Confusion Matrix:**\n",
    "  ```\n",
    "  [[13028     0     0]\n",
    "   [    0     1     0]\n",
    "   [    0     0    31]]\n",
    "  ```\n",
    "\n",
    "- **KNN** \n",
    "  - Test Accuracy: 0.85\n",
    "  - Test F1-Score: 0.83\n",
    "\n",
    "### Analisis\n",
    "- Random Forest memiliki akurasi dan F1-Score yang sempurna, menunjukkan kinerja yang sangat baik dalam mengklasifikasikan data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ph9yIYDXEPuB"
   },
   "source": [
    "## **c. Tuning Model Klasifikasi (Optional)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Bikx3LINv5e"
   },
   "source": [
    "Gunakan GridSearchCV, RandomizedSearchCV, atau metode lainnya untuk mencari kombinasi hyperparameter terbaik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "winbFzb8NL95"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy after tuning: 1.00\n",
      "Test F1-Score after tuning: 1.00\n"
     ]
    }
   ],
   "source": [
    "# Evaluasi setelah tuning\n",
    "y_pred_test_tuned = best_model.predict(X_test)\n",
    "\n",
    "# Hitung ulang metrik evaluasi\n",
    "test_accuracy_tuned = accuracy_score(y_test, y_pred_test_tuned)\n",
    "test_f1_tuned = f1_score(y_test, y_pred_test_tuned, average='weighted')\n",
    "\n",
    "print(f'Test Accuracy after tuning: {test_accuracy_tuned:.2f}')\n",
    "print(f'Test F1-Score after tuning: {test_f1_tuned:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hE7pqlEPEYzI"
   },
   "source": [
    "## **d. Evaluasi Model Klasifikasi setelah Tuning (Optional)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "feaPESoeN0zz"
   },
   "source": [
    "Berikut adalah rekomendasi tahapannya.\n",
    "1. Gunakan model dengan hyperparameter terbaik.\n",
    "2. Hitung ulang metrik evaluasi untuk melihat apakah ada peningkatan performa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HTXZRvEeNMb1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy after tuning: 1.00\n",
      "Test F1-Score after tuning: 1.00\n"
     ]
    }
   ],
   "source": [
    "# Metrik evaluasi setelah tuning\n",
    "y_pred_test_tuned = best_model.predict(X_test)\n",
    "\n",
    "# Metrik evaluasi setelah tuning\n",
    "test_accuracy_tuned = accuracy_score(y_test, y_pred_test_tuned)\n",
    "test_f1_tuned = f1_score(y_test, y_pred_test_tuned, average='weighted')\n",
    "\n",
    "print(f'Test Accuracy after tuning: {test_accuracy_tuned:.2f}')\n",
    "print(f'Test F1-Score after tuning: {test_f1_tuned:.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZRsOdm4uEgAW"
   },
   "source": [
    "## **e. Analisis Hasil Evaluasi Model Klasifikasi**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hm3BhSi6N4_l"
   },
   "source": [
    "Berikut adalah **rekomendasi** tahapannya.\n",
    "1. Bandingkan hasil evaluasi sebelum dan setelah tuning (jika dilakukan).\n",
    "2. Identifikasi kelemahan model, seperti:\n",
    "  - Precision atau Recall rendah untuk kelas tertentu.\n",
    "  - Apakah model mengalami overfitting atau underfitting?\n",
    "3. Berikan rekomendasi tindakan lanjutan, seperti mengumpulkan data tambahan atau mencoba algoritma lain jika hasil belum memuaskan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Hasil Evaluasi**\n",
    "- **Sebelum Tuning**:\n",
    "  - Test Accuracy: 1.00\n",
    "  - Test F1-Score: 1.00\n",
    "- **Setelah Tuning**:\n",
    "  - Test Accuracy: 1.00\n",
    "  - Test F1-Score: 1.00\n",
    "\n",
    "## **Analisis**\n",
    "- **Perbandingan Hasil**: Tuning model tidak hanya mempertahankan akurasi dan F1-Score yang sempurna, tetapi juga menunjukkan bahwa model bekerja dengan sangat baik pada data uji.\n",
    "- **Kelemahan Model**: Meskipun model menunjukkan performa sempurna, perlu diperhatikan bahwa hal ini mungkin menunjukkan risiko overfitting, di mana model terlalu cocok dengan data pelatihan dan mungkin tidak generalis pada data baru.\n",
    "- **Rekomendasi Tindakan Lanjutan**: \n",
    "  - Mengumpulkan data tambahan untuk menguji generalisasi model.\n",
    "  - Mencoba algoritma lain atau teknik regularisasi untuk memastikan model tetap robust.\n",
    "  - Melakukan evaluasi lebih lanjut dengan menggunakan teknik validasi silang (cross-validation) untuk memastikan stabilitas hasil.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
